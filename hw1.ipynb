{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "10316d5779a3733",
      "metadata": {
        "collapsed": false,
        "id": "10316d5779a3733",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "# Exercise 1: t-SNE\n",
        "\n",
        "## Do not start the exercise until you fully understand the submission guidelines.\n",
        "\n",
        "\n",
        "* The homework assignments are executed automatically.\n",
        "* Failure to comply with the following instructions will result in a significant penalty.\n",
        "* Appeals regarding your failure to read these instructions will be denied.\n",
        "\n",
        "## Read the following instructions carefully:\n",
        "\n",
        "1. This Jupyter notebook contains all the step-by-step instructions needed for this exercise.\n",
        "1. Write **efficient**, **vectorized** code whenever possible. Some calculations in this exercise may take several minutes when implemented efficiently, and might take much longer otherwise. Unnecessary loops will result in point deductions.\n",
        "1. You are responsible for the correctness of your code and should add as many tests as you see fit to this jupyter notebook. Tests will not be graded nor checked.\n",
        "1. You are allowed to use functions and methods from the [Python Standard Library](https://docs.python.org/3/library/).\n",
        "1. Your code must run without errors. Use at least `numpy` 1.15.4. Any code that cannot run will not be graded.\n",
        "1. Write your own code. Cheating will not be tolerated.\n",
        "1. Submission includes a zip file that contains this notebook, with your ID as the file name. For example, `hw1_123456789_987654321.zip` if you submitted in pairs and `hw1_123456789.zip` if you submitted the exercise alone. The name of the notebook should follow the same structure.\n",
        "   \n",
        "Please use only a **zip** file in your submission.\n",
        "\n",
        "---\n",
        "##❗❗❗❗❗❗❗❗❗**This is mandatory**❗❗❗❗❗❗❗❗❗\n",
        "## Please write your RUNI emails in this cell:\n",
        "\n",
        "### *** YOUR EMAILS HERE ***\n",
        "\n",
        "ariel.rabinovitch@post.runi.ac.il\n",
        "\n",
        "*לשים פה מייל של אראל*\n",
        "\n",
        "## Please sign that you have read and understood the instructions:\n",
        "\n",
        "### *** YOUR IDS HERE ***\n",
        "\n",
        "315871939\n",
        "314804568\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "735832cbfa43f83",
      "metadata": {
        "id": "735832cbfa43f83",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f877cca-f7d1-41ca-9d3d-28d587bec85c",
      "metadata": {
        "id": "8f877cca-f7d1-41ca-9d3d-28d587bec85c"
      },
      "source": [
        "# Design your algorithm\n",
        "Make sure to describe the algorithm, its limitations, and describe use-cases."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ba7760b-b4ef-45a9-9aad-88b45fd8d442",
      "metadata": {
        "id": "0ba7760b-b4ef-45a9-9aad-88b45fd8d442"
      },
      "source": [
        "t-Distributed Stochastic Neighbor Embedding (t-SNE) is a nonlinear dimensionality reduction technique designed to embed high-dimensional data into a lower-dimensional space (typically 2D or 3D), while preserving the local structure of the data. It is especially useful for visualization tasks.\n",
        "\n",
        "The core idea is to convert pairwise similarities between data points into probabilities, both in the high-dimensional space and in the lower-dimensional space, and then minimize the Kullback-Leibler (KL) divergence between these two distributions.\n",
        "\n",
        "The algorithm proceeds in three main stages:\n",
        "\n",
        "##### Stage 1: Compute Pairwise Similarities in High Dimensions\n",
        "\n",
        "For each data point ​​$x_i$, we model the conditional probability ​$p_{i|j}$ that ​$x_i$ would pick ​$x_j$ as its neighbor, using a Gaussian distribution centered at ​$x_i$.\n",
        "\n",
        "The bandwidth (standard deviation) of this Gaussian is determined via perplexity, a hyperparameter that controls the effective number of neighbors.\n",
        "\n",
        "We then symmetrize the probabilities using:\n",
        "\n",
        "$$p_{ij} = \\frac{p_{j|i} + p_{i|j}}{2n}$$\n",
        "\n",
        "##### Stage 2: Compute Pairwise Similarities in Low Dimensions\n",
        "\n",
        "We initialize the low-dimensional representations ​$y_i$ randomly.\n",
        "\n",
        "Pairwise similarities ​​$q_{ij}$ between points ​$y_i$ and $y_j$ are computed using a Student t-distribution with one degree of freedom:\n",
        "\n",
        "$$q_{ij} = \\frac{(1 + \\|y_i - y_j\\|^2)^{-1}}{\\sum_{k \\ne l} (1 + \\|y_k - y_l\\|^2)^{-1}}$$\n",
        "\n",
        "##### Stage 3: Optimize via Gradient Descent\n",
        "\n",
        "We minimize the Kullback-Leibler divergence between the high-dimensional and low-dimensional similarity distributions:\n",
        "\n",
        "$$KL(P \\| Q) = \\sum_i \\sum_j p_{ij} \\log \\frac{p_{ij}}{q_{ij}}$$\n",
        "\n",
        "\n",
        "## Hyperparameters\n",
        "\n",
        "- Perplexity: Controls local neighborhood size in high-dimensional space; typically between 5 and 50.\n",
        "\n",
        "- Learning rate: Affects the step size during gradient descent.\n",
        "\n",
        "- Number of iterations: Total optimization steps, usually a few hundred to a few thousand.\n",
        "\n",
        "- Initialization: Usually with small random values or PCA-reduced space.\n",
        "\n",
        "\n",
        "### Optimization Strategy\n",
        "\n",
        "We use *gradient descent* to minimize the KL divergence. To improve convergence:\n",
        "\n",
        "### Limitations\n",
        "\n",
        "- Poor performance in preserving global structure of data.\n",
        "\n",
        "- Non-parametric: doesn't naturally support adding new data points\n",
        "\n",
        "### Use-Cases\n",
        "\n",
        "- Visualizing clusters in high-dimensional data (e.g., MNIST, word embeddings).\n",
        "\n",
        "- Exploratory data analysis where interpretability of local relationships is critical.\n",
        "\n",
        "- Understanding structure in embeddings from neural networks or feature spaces.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2158ff2629daf2bb",
      "metadata": {
        "collapsed": false,
        "id": "2158ff2629daf2bb",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "# Your implementations\n",
        "You may add new cells, write helper functions or test code as you see fit.\n",
        "Please use the cell below and include a description of your implementation.\n",
        "Explain code design consideration, algorithmic choices and any other details you think is relevant to understanding your implementation.\n",
        "Failing to explain your code will lead to point deductions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afe206c9-d1f4-440b-aca0-c807cdd79451",
      "metadata": {
        "id": "afe206c9-d1f4-440b-aca0-c807cdd79451"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7b85d8f7447ebce0",
      "metadata": {
        "id": "7b85d8f7447ebce0",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "class CustomTSNE:\n",
        "    def __init__(self, perplexity=30.0, n_components=2, n_iter=1000, learning_rate=200.0):\n",
        "        self.perplexity = perplexity\n",
        "        self.n_components = n_components\n",
        "        self.n_iter = n_iter\n",
        "        self.learning_rate = learning_rate\n",
        "        self.X = None\n",
        "        self.Y = None\n",
        "        self.P = None  # High-dimensional similarities\n",
        "        \n",
        "    def _compute_pairwise_distances(self, X):\n",
        "        \"\"\"Compute pairwise Euclidean distances between points.\"\"\"\n",
        "        sum_X = np.sum(np.square(X), axis=1)\n",
        "        D = np.add(np.add(-2 * np.dot(X, X.T), sum_X).T, sum_X)\n",
        "        return D\n",
        "    \n",
        "    def _binary_search_perplexity(self, distances, perplexity, tol=1e-5, max_iter=50):\n",
        "        \"\"\"Binary search for sigma that achieves target perplexity.\"\"\"\n",
        "        n = distances.shape[0]\n",
        "        beta = np.ones(n)\n",
        "        beta_min = np.full(n, -np.inf)\n",
        "        beta_max = np.full(n, np.inf)\n",
        "        log_perp = np.log(perplexity)\n",
        "        \n",
        "        for i in range(max_iter):\n",
        "            # Compute probabilities\n",
        "            P = np.exp(-distances * beta[:, np.newaxis])\n",
        "            P[range(n), range(n)] = 0  # Set diagonal to 0\n",
        "            sum_P = np.sum(P, axis=1)\n",
        "            P = P / sum_P[:, np.newaxis]\n",
        "            \n",
        "            # Compute entropy\n",
        "            entropy = -np.sum(P * np.log(P + 1e-10))\n",
        "            \n",
        "            # Binary search\n",
        "            if np.abs(entropy - log_perp) < tol:\n",
        "                break\n",
        "                \n",
        "            if entropy > log_perp:\n",
        "                beta_min = beta.copy()\n",
        "                if np.all(beta_max == np.inf):\n",
        "                    beta *= 2\n",
        "                else:\n",
        "                    beta = (beta + beta_max) / 2\n",
        "            else:\n",
        "                beta_max = beta.copy()\n",
        "                if np.all(beta_min == -np.inf):\n",
        "                    beta /= 2\n",
        "                else:\n",
        "                    beta = (beta + beta_min) / 2\n",
        "                    \n",
        "        return P\n",
        "    \n",
        "    def _compute_high_dim_similarities(self, X):\n",
        "        \"\"\"Compute pairwise similarities in high-dimensional space.\"\"\"\n",
        "        distances = self._compute_pairwise_distances(X)\n",
        "        P = self._binary_search_perplexity(distances, self.perplexity)\n",
        "        # Symmetrize the probabilities\n",
        "        P = (P + P.T) / (2 * P.shape[0])\n",
        "        return P\n",
        "    \n",
        "    def _compute_low_dim_similarities(self, Y):\n",
        "        \"\"\"Compute pairwise similarities in low-dimensional space using t-distribution.\"\"\"\n",
        "        distances = self._compute_pairwise_distances(Y)\n",
        "        Q = 1 / (1 + distances)\n",
        "        np.fill_diagonal(Q, 0)\n",
        "        Q = Q / np.sum(Q)\n",
        "        return Q\n",
        "    \n",
        "    def _compute_gradient(self, Y, P, Q):\n",
        "        \"\"\"Compute gradient of KL divergence with respect to Y.\"\"\"\n",
        "        n = Y.shape[0]\n",
        "        dY = np.zeros((n, self.n_components))\n",
        "        \n",
        "        # Vectorized gradient computation\n",
        "        for i in range(n):\n",
        "            # Compute differences between point i and all other points\n",
        "            diff = Y[i] - Y  # Shape: (n, n_components)\n",
        "            # Compute squared distances\n",
        "            dist_sq = np.sum(diff**2, axis=1)  # Shape: (n,)\n",
        "            # Compute the gradient contribution from all points\n",
        "            grad = 4 * (P[i] - Q[i])[:, np.newaxis] * diff / (1 + dist_sq)[:, np.newaxis]\n",
        "            # Sum up all contributions\n",
        "            dY[i] = np.sum(grad, axis=0)\n",
        "            \n",
        "        return dY\n",
        "    \n",
        "    def fit_transform(self, X):\n",
        "        \"\"\"Fit t-SNE to the data and return the transformed data.\"\"\"\n",
        "        self.X = X\n",
        "        n = X.shape[0]\n",
        "        \n",
        "        print(\"Computing high-dimensional similarities...\")\n",
        "        # Step 1: Compute high-dimensional similarities\n",
        "        self.P = self._compute_high_dim_similarities(X)\n",
        "        \n",
        "        # Initialize Y randomly\n",
        "        self.Y = np.random.randn(n, self.n_components) * 1e-4\n",
        "        \n",
        "        print(\"Starting gradient descent...\")\n",
        "        # Gradient descent\n",
        "        for i in range(self.n_iter):\n",
        "            if i % 100 == 0:  # Print progress every 100 iterations\n",
        "                print(f\"Iteration {i}/{self.n_iter}\")\n",
        "                \n",
        "            # Compute low-dimensional similarities\n",
        "            Q = self._compute_low_dim_similarities(self.Y)\n",
        "            \n",
        "            # Compute gradient\n",
        "            dY = self._compute_gradient(self.Y, self.P, Q)\n",
        "            \n",
        "            # Update Y\n",
        "            self.Y = self.Y - self.learning_rate * dY\n",
        "            \n",
        "            # Center Y\n",
        "            self.Y = self.Y - np.mean(self.Y, axis=0)\n",
        "        \n",
        "        print(\"t-SNE completed!\")\n",
        "        return self.Y\n",
        "    \n",
        "    def transform(self, X_original, Y_original, X_new):\n",
        "        \"\"\"Transform new data points into the existing t-SNE layout.\"\"\"\n",
        "        # Compute distances between new points and original points\n",
        "        distances = np.zeros((X_new.shape[0], X_original.shape[0]))\n",
        "        for i in range(X_new.shape[0]):\n",
        "            distances[i] = np.sum((X_original - X_new[i])**2, axis=1)\n",
        "        \n",
        "        # Compute similarities using t-distribution\n",
        "        similarities = 1 / (1 + distances)\n",
        "        \n",
        "        # Weighted average of original points' positions\n",
        "        Y_new = np.zeros((X_new.shape[0], self.n_components))\n",
        "        for i in range(X_new.shape[0]):\n",
        "            weights = similarities[i] / np.sum(similarities[i])\n",
        "            Y_new[i] = np.sum(Y_original * weights[:, np.newaxis], axis=0)\n",
        "            \n",
        "        return Y_new"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df24f179351fa008",
      "metadata": {
        "collapsed": false,
        "id": "df24f179351fa008",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "# Load data\n",
        "Please use the cell below to discuss your dataset choice and why it is appropriate (or not) for this algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74c4083f-5267-44d3-89ed-65864f82aa57",
      "metadata": {
        "id": "74c4083f-5267-44d3-89ed-65864f82aa57"
      },
      "source": [
        "We choosed to used the MNSIT dataset for the following resons:\n",
        "1. It is high dimensional dataset (784 dimensions, 28 X 28 pixels)\n",
        "2. Has clear class structure (10 digits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a14a3b8890e86f9",
      "metadata": {
        "id": "a14a3b8890e86f9",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set shape: (4000, 784)\n",
            "Test set shape: (1000, 784)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load data\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
        "X = X.astype('float32')\n",
        "y = y.astype('int')\n",
        "\n",
        "# Normalize data if necessary\n",
        "X = (X - X.min()) / (X.max() - X.min()) # Min-Max\n",
        "\n",
        "# Split the data into train and test\n",
        "n_samples = 5000  # Using 5000 samples for demonstration\n",
        "X = X[:n_samples]\n",
        "y = y[:n_samples]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "\n",
        "\n",
        "# Visualize some sample digits\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    plt.imshow(X_train[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title(f'Digit: {y_train[i]}')\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da49bb42f79a55f",
      "metadata": {
        "collapsed": false,
        "id": "da49bb42f79a55f",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "# t-SNE demonstration\n",
        "Demonstrate your t-SNE implementation.\n",
        "\n",
        "Add plots and figures. The code below is just to help you get started, and should not be your final submission.\n",
        "\n",
        "Please use the cell below to describe your results and tests.\n",
        "\n",
        "Describe the difference between your implementation and the sklearn implementation. Hint: you can look at the documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a064afb5-aeea-48d8-b315-921bf4f8238f",
      "metadata": {
        "id": "a064afb5-aeea-48d8-b315-921bf4f8238f"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9b3628856e1335fd",
      "metadata": {
        "id": "9b3628856e1335fd",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing high-dimensional similarities...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/98/vlk1t3vj1n16bfcdcs5bt09w0000gn/T/ipykernel_75699/2451854459.py:30: RuntimeWarning: invalid value encountered in divide\n",
            "  P = P / sum_P[:, np.newaxis]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting gradient descent...\n",
            "Iteration 0/1000\n",
            "Iteration 100/1000\n",
            "Iteration 200/1000\n",
            "Iteration 300/1000\n",
            "Iteration 400/1000\n",
            "Iteration 500/1000\n",
            "Iteration 600/1000\n",
            "Iteration 700/1000\n",
            "Iteration 800/1000\n",
            "Iteration 900/1000\n",
            "t-SNE completed!\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'N' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m custom_Y \u001b[38;5;241m=\u001b[39m custom_tsne\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Run sklearn t-SNE\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m sk_tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m, perplexity\u001b[38;5;241m=\u001b[39m\u001b[43mN\u001b[49m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     14\u001b[0m sk_Y \u001b[38;5;241m=\u001b[39m sk_tsne\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Visualization of the result\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'N' is not defined"
          ]
        }
      ],
      "source": [
        "# Run your custom t-SNE implementation\n",
        "# Initialize and run custom t-SNE\n",
        "custom_tsne = CustomTSNE(\n",
        "    perplexity=30.0,  # Typical value for MNIST\n",
        "    n_components=2,   # 2D visualization\n",
        "    n_iter=1000,      # Number of iterations\n",
        "    learning_rate=200.0  # Learning rate for gradient descent\n",
        ")\n",
        "\n",
        "custom_Y = custom_tsne.fit_transform(X_train)\n",
        "\n",
        "# Run sklearn t-SNE\n",
        "sk_tsne = TSNE(n_components=2, init='random', perplexity=N/10)\n",
        "sk_Y = sk_tsne.fit_transform(X_train)\n",
        "\n",
        "# Visualization of the result\n",
        "plt.figure()\n",
        "plt.scatter(custom_Y[:, 0], custom_Y[:, 1], s=5, c=label_train.astype(int), cmap='tab10')\n",
        "plt.scatter(custom_Y[:, 0], custom_Y[:, 1], s=5, c=label_train.astype(int), cmap='tab10')\n",
        "plt.colorbar()\n",
        "plt.title('MNIST Data Embedded into 2D with Custom t-SNE')\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(sk_Y[:, 0], sk_Y[:, 1], s=5, c=label_train.astype(int), cmap='tab10')\n",
        "plt.colorbar()\n",
        "plt.title('MNIST Data Embedded into 2D with sklearn t-SNE')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73fa2fceedc77e92",
      "metadata": {
        "collapsed": false,
        "id": "73fa2fceedc77e92",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "# t-SNE extension - mapping new samples\n",
        "Demonstrate your t-SNE transformation procedure.\n",
        "\n",
        "Add plots and figures.\n",
        "\n",
        "Please use the cell below t describe your suggested approach in detail. Use formal notations where appropriate.\n",
        "Describe and discuss your results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b34701c-cc3b-439a-b2d0-393449cf5a20",
      "metadata": {
        "id": "7b34701c-cc3b-439a-b2d0-393449cf5a20"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d38dc132b23e7b",
      "metadata": {
        "id": "9d38dc132b23e7b",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "# Transform new data\n",
        "custom_Y_new = custom_tsne.transform(X_train,custom_Y,X_test)\n",
        "\n",
        "# Visualization of the result\n",
        "plt.figure()\n",
        "plt.scatter(custom_Y[:, 0], custom_Y[:, 1], s=5, c=label_train.astype(int), cmap='tab10')\n",
        "plt.scatter(custom_Y_new[:, 0], custom_Y_new[:, 1], marker = '*', s=50, linewidths=0.5, edgecolors='k', c=label_test.astype(int), cmap='tab10')\n",
        "plt.colorbar()\n",
        "plt.title('MNIST Data Embedded into 2D with Custom t-SNE')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18c95c7f-d3a9-4e3d-b539-02e020358766",
      "metadata": {
        "id": "18c95c7f-d3a9-4e3d-b539-02e020358766"
      },
      "source": [
        "# Use of generative AI\n",
        "Please use the cell below to describe your use of generative AI in this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36753fd7-8b2d-487b-82ae-dc318eca3ca6",
      "metadata": {
        "id": "36753fd7-8b2d-487b-82ae-dc318eca3ca6"
      },
      "source": [
        "Used Generative AI (Claude) to understand the algorithm better and consildate with it about implementation specifics "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
